name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: requirements.txt
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y graphviz
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run unit tests
        id: unit_tests
        run: |
          pytest tests/unit/ -v --cov=app --cov-report=xml --cov-report=term-missing --cov-report=json 2>&1 | tee test-output.log
      
      - name: Parse test results
        id: parse_results
        if: always()
        run: |
          # Initialize defaults
          PASSED="0"
          FAILED="0"
          WARNINGS="0"
          COVERAGE="0%"
          
          # Extract test summary from output
          if [ -f test-output.log ]; then
            PASSED=$(grep -oP '\d+(?= passed)' test-output.log | head -1 || echo "0")
            FAILED=$(grep -oP '\d+(?= failed)' test-output.log | head -1 || echo "0")
            WARNINGS=$(grep -oP '\d+(?= warnings)' test-output.log | head -1 || echo "0")
            COVERAGE=$(grep -oP 'TOTAL.*\d+%' test-output.log | grep -oP '\d+\.\d+%' | head -1 || echo "0%")
          fi
          
          # Ensure values are set (handle empty strings)
          PASSED=${PASSED:-"0"}
          FAILED=${FAILED:-"0"}
          WARNINGS=${WARNINGS:-"0"}
          COVERAGE=${COVERAGE:-"0%"}
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "warnings=$WARNINGS" >> $GITHUB_OUTPUT
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
      
      - name: Generate test report
        if: always()
        run: |
          # Set defaults if outputs are empty
          PASSED="${{ steps.parse_results.outputs.passed }}"
          FAILED="${{ steps.parse_results.outputs.failed }}"
          WARNINGS="${{ steps.parse_results.outputs.warnings }}"
          COVERAGE="${{ steps.parse_results.outputs.coverage }}"
          
          PASSED=${PASSED:-"0"}
          FAILED=${FAILED:-"0"}
          WARNINGS=${WARNINGS:-"0"}
          COVERAGE=${COVERAGE:-"0%"}
          
          echo "## âœ… Unit Tests Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| âœ… Passed | $PASSED |" >> $GITHUB_STEP_SUMMARY
          echo "| âŒ Failed | $FAILED |" >> $GITHUB_STEP_SUMMARY
          echo "| âš ï¸ Warnings | $WARNINGS |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“Š Coverage | $COVERAGE |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$FAILED" != "0" ]; then
            echo "### âš ï¸ Test Failures Detected" >> $GITHUB_STEP_SUMMARY
            echo "Check the test output above for details." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Add coverage details if available
          if [ -f coverage.json ]; then
            echo "### Coverage Details" >> $GITHUB_STEP_SUMMARY
            echo "Coverage report is available in the artifacts section." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-logs
          path: test-output.log
          retention-days: 7
          if-no-files-found: ignore
      
      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-coverage-reports
          path: |
            coverage.xml
            coverage.json
            htmlcov/
          retention-days: 30
          if-no-files-found: ignore
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unit
          name: unit-tests
        continue-on-error: true

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: requirements.txt
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y graphviz
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run integration tests
        id: integration_tests
        env:
          # Add test API keys if needed (can be set as GitHub secrets)
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          CIPHER_API_KEY: ${{ secrets.CIPHER_API_KEY }}
          REPLICATE_API_KEY: ${{ secrets.REPLICATE_API_KEY }}
        run: |
          pytest tests/integration/ -v -m integration --cov=app --cov-report=term --cov-report=json 2>&1 | tee test-output.log || true
        continue-on-error: true
      
      - name: Parse integration test results
        id: parse_integration_results
        if: always()
        run: |
          # Initialize defaults
          PASSED="0"
          FAILED="0"
          SKIPPED="0"
          
          # Extract test summary from output
          if [ -f test-output.log ]; then
            PASSED=$(grep -oP '\d+(?= passed)' test-output.log | head -1 || echo "0")
            FAILED=$(grep -oP '\d+(?= failed)' test-output.log | head -1 || echo "0")
            SKIPPED=$(grep -oP '\d+(?= skipped)' test-output.log | head -1 || echo "0")
          fi
          
          # Ensure values are set (handle empty strings)
          PASSED=${PASSED:-"0"}
          FAILED=${FAILED:-"0"}
          SKIPPED=${SKIPPED:-"0"}
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
      
      - name: Generate integration test report
        if: always()
        run: |
          # Set defaults if outputs are empty
          PASSED="${{ steps.parse_integration_results.outputs.passed }}"
          FAILED="${{ steps.parse_integration_results.outputs.failed }}"
          SKIPPED="${{ steps.parse_integration_results.outputs.skipped }}"
          
          PASSED=${PASSED:-"0"}
          FAILED=${FAILED:-"0"}
          SKIPPED=${SKIPPED:-"0"}
          
          echo "## ðŸ”— Integration Tests Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| âœ… Passed | $PASSED |" >> $GITHUB_STEP_SUMMARY
          echo "| âŒ Failed | $FAILED |" >> $GITHUB_STEP_SUMMARY
          echo "| â­ï¸ Skipped | $SKIPPED |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$FAILED" != "0" ]; then
            echo "### âš ï¸ Integration Test Failures" >> $GITHUB_STEP_SUMMARY
            echo "Some integration tests failed. This may be expected if API keys are not configured." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "$SKIPPED" != "0" ]; then
            echo "### â„¹ï¸ Skipped Tests" >> $GITHUB_STEP_SUMMARY
            echo "Some tests were skipped, likely due to missing API keys or external service dependencies." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload integration test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-logs
          path: test-output.log
          retention-days: 7
          if-no-files-found: ignore

  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: [unit-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        id: docker_build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: false
          load: true
          tags: creative-service:test
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Test Docker image
        run: |
          docker run --rm creative-service:test python -c "import app; print('Image works!')"
      
      - name: Generate Docker build report
        if: always()
        run: |
          echo "## ðŸ³ Docker Build Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Build Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ job.status }}" == "success" ]; then
            echo "âœ… **Docker image built successfully**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Image tag: \`creative-service:test\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The image has been validated and is ready for deployment." >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Docker build failed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check the build logs above for details." >> $GITHUB_STEP_SUMMARY
          fi

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, docker-build]
    if: always()
    
    steps:
      - name: Generate overall summary
        run: |
          echo "## ðŸ“Š CI Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Job Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.unit-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Docker Build | ${{ needs.docker-build.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Determine overall status
          if [ "${{ needs.unit-tests.result }}" == "success" ] && \
             [ "${{ needs.docker-build.result }}" == "success" ]; then
            echo "### âœ… Overall Status: Success" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All critical checks passed. The service is ready for deployment." >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Overall Status: Failure" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Some checks failed. Please review the job logs above." >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts Available" >> $GITHUB_STEP_SUMMARY
          echo "- Unit test logs and coverage reports" >> $GITHUB_STEP_SUMMARY
          echo "- Integration test logs" >> $GITHUB_STEP_SUMMARY
          echo "- Coverage HTML reports (in artifacts)" >> $GITHUB_STEP_SUMMARY

